{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 2.0.2\n",
      "pandas 2.2.3\n",
      "torch 2.6.0+cu126\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for module in np, pd, torch:\n",
    "    print(module.__name__, module.__version__)\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_ds, valid_ds = random_split(train_ds, [55000, 5000], torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = nn.Sequential(\n",
    "    Normalize([0.2856], [0.3202])\n",
    ")   # 对每个通道进行标准化 对于FashionMNIST灰度图只有一个通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, activation=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.activation = F.relu if activation == \"relu\" else F.selu\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,   out_channels=32,  kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,  out_channels=32,  kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32,  out_channels=64,  kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64,  out_channels=64,  kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=64,  out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        act = self.activation\n",
    "        x = self.pool(act(self.conv2(act(self.conv1(x)))))\n",
    "        x = self.pool(act(self.conv4(act(self.conv3(x)))))\n",
    "        x = self.pool(act(self.conv6(act(self.conv5(x)))))\n",
    "        x = self.fc2(act(self.fc1(self.flatten(x))))\n",
    "        \n",
    "        return x\n",
    "\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        act = self.activation\n",
    "        print(x.shape)\n",
    "        x = act(self.conv1(x))  # [1, 28, 28]   --> [32, 28, 28]\n",
    "        print(x.shape)\n",
    "        x = act(self.conv2(x))  # [32, 28, 28]  --> [32, 28, 28]\n",
    "        print(x.shape)\n",
    "        x = self.pool(x)        # [32, 28, 28]  --> [32, 14, 14]\n",
    "        print(x.shape)\n",
    "        x = act(self.conv3(x))  # [32, 14, 14]  --> [64, 14, 14]\n",
    "        print(x.shape)\n",
    "        x = act(self.conv4(x))  # [64, 14, 14]  --> [64, 14, 14]\n",
    "        print(x.shape)\n",
    "        x = self.pool(x)        # [64, 14, 14]  --> [64, 7, 7]\n",
    "        print(x.shape)\n",
    "        x = act(self.conv5(x))  # [64, 7, 7]    --> [128, 7, 7]\n",
    "        print(x.shape)\n",
    "        x = act(self.conv6(x))  # [128, 7, 7]   --> [128, 7, 7]\n",
    "        print(x.shape)\n",
    "        x = self.pool(x)        # [128, 7, 7]   --> [128, 3, 3]\n",
    "        print(x.shape)\n",
    "\n",
    "        x = self.flatten(x) # 128 * 3 * 3 --> 1152\n",
    "        print(x.shape)\n",
    "\n",
    "        x = act(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopCallback:\n",
    "    def __init__(self, patience=5, min_delta=0.01):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_metric = -1\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, metric):\n",
    "        if metric > self.best_metric + self.min_delta:\n",
    "            self.best_metric = metric\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "    @property\n",
    "    def early_stop(self):\n",
    "        return self.counter >= self.patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluating(model, dataloader, loss_function):\n",
    "    loss_list  = []\n",
    "    pred_list  = []\n",
    "    label_list = []\n",
    "\n",
    "    for datas, labels in dataloader:\n",
    "        datas  = datas.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = model(datas)\n",
    "        loss = loss_function(logits, labels)\n",
    "        loss_list.append(loss.item())\n",
    "        preds = logits.argmax(axis=-1)\n",
    "        pred_list.extend(preds.cpu().numpy().tolist())\n",
    "        label_list.extend(labels.cpu().numpy().tolist())\n",
    "\n",
    "    acc = accuracy_score(label_list, pred_list)\n",
    "\n",
    "    return np.mean(loss_list), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_base(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        valid_dataloader,\n",
    "        loss_function,\n",
    "        optimizer,\n",
    "        epoch,\n",
    "        early_stor_cb = None,\n",
    "        eval_step = 500\n",
    "):\n",
    "    record_dict = {\"train\":[], \"valid\":[]}\n",
    "    global_step = 0\n",
    "    model.train()\n",
    "    with tqdm(total=epoch * len(train_dataloader)) as pbar:\n",
    "        for epoch_id in range(epoch):\n",
    "            for datas, labels in train_dataloader:\n",
    "                datas = datas.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(datas)\n",
    "                loss = loss_function(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                preds = logits.argmax(axis=-1)\n",
    "                acc = accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n",
    "                loss = loss.cpu().item()\n",
    "                record_dict[\"train\"].append({\"loss\":loss, \"acc\":acc, \"step\":global_step})\n",
    "\n",
    "                if global_step % eval_step == 0:\n",
    "                    model.eval()\n",
    "                    valid_loss, valid_acc = evaluating(model, valid_dataloader, loss_function)\n",
    "                    record_dict[\"valid\"].append({\"loss\":valid_loss, \"acc\":valid_acc, \"step\":global_step})\n",
    "                    model.train()\n",
    "\n",
    "                    if early_stor_cb is not None:\n",
    "                        early_stor_cb(valid_acc)\n",
    "                        if early_stor_cb.early_stop:\n",
    "                            print(f\"Early stop at epoch : {epoch_id}, global_step : {global_step}\")\n",
    "                            return record_dict\n",
    "                global_step += 1\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\"epoch\":epoch_id})\n",
    "\n",
    "    return record_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(record_dict, sample_step=500):\n",
    "    train_df = pd.DataFrame(record_dict[\"train\"]).set_index(\"step\").iloc[::sample_step]\n",
    "    valid_df = pd.DataFrame(record_dict[\"valid\"]).set_index(\"step\")\n",
    "    \n",
    "    fig_num = len(train_df.columns)\n",
    "    fig, axs = plt.subplots(1, fig_num, figsize=(5 * fig_num, 5))\n",
    "    for idx, item in enumerate(train_df.columns):    \n",
    "        axs[idx].plot(train_df.index, train_df[item], label=f\"train_{item}\")\n",
    "        axs[idx].plot(valid_df.index, valid_df[item], label=f\"valid_{item}\")\n",
    "        axs[idx].grid()\n",
    "        axs[idx].legend()\n",
    "        axs[idx].set_xticks(range(0, train_df.index[-1], 5000))\n",
    "        axs[idx].set_xticklabels(map(lambda x: f\"{int(x/1000)}k\", range(0, train_df.index[-1], 5000)))\n",
    "        axs[idx].set_xlabel(\"step\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(\"relu\")\n",
    "early_stop_cb = EarlyStopCallback()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "model = model.to(device)\n",
    "record = training_base(model, train_loader, valid_loader, loss_function, optimizer, 20, early_stop_cb, eval_step=1000)\n",
    "plot_learning_curve(record, sample_step=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 2.3093442916870117, 'acc': 0.0625, 'step': 0},\n",
       " {'loss': 2.3058431148529053, 'acc': 0.0625, 'step': 1},\n",
       " {'loss': 2.3048465251922607, 'acc': 0.03125, 'step': 2},\n",
       " {'loss': 2.3020904064178467, 'acc': 0.125, 'step': 3},\n",
       " {'loss': 2.2993860244750977, 'acc': 0.03125, 'step': 4},\n",
       " {'loss': 2.3038411140441895, 'acc': 0.125, 'step': 5},\n",
       " {'loss': 2.303762435913086, 'acc': 0.15625, 'step': 6},\n",
       " {'loss': 2.305441379547119, 'acc': 0.09375, 'step': 7},\n",
       " {'loss': 2.3050379753112793, 'acc': 0.09375, 'step': 8},\n",
       " {'loss': 2.3088085651397705, 'acc': 0.09375, 'step': 9}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "record[\"train\"][0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
