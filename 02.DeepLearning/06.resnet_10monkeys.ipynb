{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 2.0.2\n",
      "pandas 2.2.3\n",
      "torch 2.6.0+cu126\n",
      "cuda:0\n",
      "NVIDIA GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose, Resize, ConvertImageDtype\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pathlib import Path\n",
    "\n",
    "for module in np, pd, torch:\n",
    "    print(module.__name__, module.__version__)\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./archive\")\n",
    "\n",
    "class MonkeyDataset(datasets.ImageFolder):\n",
    "    def __init__(self, mode, transform = None):\n",
    "        if mode == \"train\":\n",
    "            root = DATA_DIR / \"training\"\n",
    "        elif mode == \"valid\":\n",
    "            root = DATA_DIR / \"validation\"\n",
    "\n",
    "        super().__init__(root, transform)\n",
    "        self.imgs = self.samples\n",
    "        self.targets = [s[1] for s in self.samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopCallBack:\n",
    "    def __init__(self, patience = 5, min_delta = 0.01):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_metric = -1\n",
    "    \n",
    "    def __call__(self, metric):\n",
    "        if metric > self.best_metric + self.min_delta:\n",
    "            self.best_metric = metric\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "    \n",
    "    @property\n",
    "    def early_stop(self):\n",
    "        return self.counter >= self.patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride1, stride2, padding):\n",
    "        super().__init__()\n",
    "        self.activation = F.relu\n",
    "        self.conv1 = nn.Conv2d(in_channels,  out_channels, kernel_size, stride1, padding)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride2, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        if in_channels != out_channels:\n",
    "            self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2, padding=0) \n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        act = self.activation\n",
    "        bn = self.bn\n",
    "        fx = bn(self.conv2(act(bn(self.conv1(x)))))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            x = bn(self.downsample(x))\n",
    "\n",
    "        return act(fx + x)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)  # (224 + 2*3 - 7)//2 + 1 ==> 112\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)    # (112 + 2*1 - 3)//2 + 1 ==> 56\n",
    "        self.conv2_x = nn.Sequential(\n",
    "            ResBlock(in_channels=64,  out_channels=64,  kernel_size=3, stride1=1, stride2=1, padding=1), # (56 + 2*1 - 3)//1 + 1 ==> 56, (56 + 2*1 - 3)//1 + 1 ==> 56\n",
    "            ResBlock(in_channels=64,  out_channels=64,  kernel_size=3, stride1=1, stride2=1, padding=1)  # (56 + 2*1 - 3)//1 + 1 ==> 56, (56 + 2*1 - 3)//1 + 1 ==> 56\n",
    "        )\n",
    "        self.conv3_x = nn.Sequential(\n",
    "            ResBlock(in_channels=64,  out_channels=128, kernel_size=3, stride1=2, stride2=1, padding=1), # (56 + 2*1 - 3)//2 + 1 ==> 28, (28 + 2*1 - 3)//1 + 1 ==> 28 \n",
    "            ResBlock(in_channels=128, out_channels=128, kernel_size=3, stride1=1, stride2=1, padding=1)  # (28 + 2*1 - 3)//1 + 1 ==> 28, (28 + 2*1 - 3)//1 + 1 ==> 28\n",
    "        )\n",
    "        self.conv4_x = nn.Sequential(\n",
    "            ResBlock(in_channels=128, out_channels=256, kernel_size=3, stride1=2, stride2=1, padding=1), # (28 + 2*1 - 3)//2 + 1 ==> 14, (14 + 2*1 - 3)//1 + 1 ==> 14\n",
    "            ResBlock(in_channels=256, out_channels=256, kernel_size=3, stride1=1, stride2=1, padding=1)  # (14 + 2*1 - 3)//1 + 1 ==> 14, (14 + 2*1 - 3)//1 + 1 ==> 14\n",
    "        )\n",
    "        self.conv5_x = nn.Sequential(\n",
    "            ResBlock(in_channels=256, out_channels=512, kernel_size=3, stride1=2, stride2=1, padding=1), # (14 + 2*1 - 3)//2 + 1 ==> 7, (7 + 2*1 - 3)//1 + 1 ==> 7\n",
    "            ResBlock(in_channels=512, out_channels=512, kernel_size=3, stride1=1, stride2=1, padding=1)  # ( 7 + 2*1 - 3)//1 + 1 ==> 7, (7 + 2*1 - 3)//1 + 1 ==> 7\n",
    "        )\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(in_features=512, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.conv2_x(x)\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc(self.flatten(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.5"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluating(model, valid_dataloader, loss_function):\n",
    "    loss_list  = []\n",
    "    pred_list  = []\n",
    "    label_list = []\n",
    "\n",
    "    for imgs, labels in valid_dataloader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = model(imgs)\n",
    "        pred = logits.argmax(axis=-1)\n",
    "        loss = loss_function(logits, labels)\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        pred_list.extend(pred.cpu().numpy().tolist())\n",
    "        label_list.extend(labels.cpu().numpy().tolist())\n",
    "    \n",
    "    acc = accuracy_score(label_list, pred_list)\n",
    "\n",
    "    return np.mean(loss_list), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        valid_dataloader,\n",
    "        epoch,\n",
    "        loss_function,\n",
    "        optimizer,\n",
    "        early_stop_cb=None,\n",
    "        eval_step=500\n",
    "):\n",
    "    model.train()\n",
    "    record_dict = {\"train\":[], \"valid\":[]}\n",
    "    global_step = 0\n",
    "    with tqdm(total=epoch*len(train_dataloader)) as pbar:\n",
    "        for epoch_id in range(epoch):\n",
    "            for imgs, labels in train_dataloader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(imgs)\n",
    "                loss = loss_function(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                loss = loss.cpu().item()\n",
    "                pred = logits.argmax(axis=-1)\n",
    "                acc = accuracy_score(labels.cpu().numpy(), pred.cpu().numpy())\n",
    "                \n",
    "                record_dict[\"train\"].append({\"loss\":loss, \"acc\":acc, \"step\":global_step})\n",
    "\n",
    "                if global_step % eval_step == 0:\n",
    "                    model.eval()\n",
    "                    valid_loss, valid_acc = evaluating(model, valid_dataloader, loss_function)\n",
    "                    model.train()\n",
    "\n",
    "                    record_dict[\"valid\"].append({\"loss\":valid_loss, \"acc\":valid_acc, \"step\":global_step})\n",
    "                    \n",
    "                    if early_stop_cb is not None:\n",
    "                        early_stop_cb(valid_acc)\n",
    "                        if early_stop_cb.early_stop:\n",
    "                            print(f\"Early Stop at step:{epoch_id} / global_step:{global_step}\")\n",
    "                            return record_dict\n",
    "                \n",
    "                global_step += 1\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\"epoch_id\":epoch_id})\n",
    "    \n",
    "    return record_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(record_dict, sample_step=500):\n",
    "    train_df = pd.DataFrame(record_dict[\"train\"]).set_index(\"step\").iloc[::sample_step]\n",
    "    valid_df = pd.DataFrame(record_dict[\"valid\"]).set_index(\"step\")\n",
    "    fig_num = len(train_df.columns)\n",
    "    fig, axs = plt.subplots(1, fig_num, figsize=(5*fig_num, 5))\n",
    "    for idx, item in enumerate(train_df.columns):\n",
    "        axs[idx].plot(train_df.index, train_df[item], label=f\"train_{item}\")\n",
    "        axs[idx].plot(valid_df.index, valid_df[item], label=f\"valid_{item}\")\n",
    "        axs[idx].grid()\n",
    "        axs[idx].legend()\n",
    "        axs[idx].set_xlabel(\"step\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "img_h, img_w = 224, 224\n",
    "\n",
    "transformer = Compose([\n",
    "    Resize((img_h, img_w)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ConvertImageDtype(torch.float)\n",
    "])\n",
    "\n",
    "train_dataset = MonkeyDataset(mode=\"train\", transform=transformer)\n",
    "valid_dataset = MonkeyDataset(mode=\"valid\", transform=transformer)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0517, -0.0888, -0.0508, -0.0006, -0.0503, -0.0805,  0.0388, -0.0194,\n",
       "          0.0283, -0.0229]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet().to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "early_stop_cb = EarlyStopCallBack()\n",
    "\n",
    "epoch = 20\n",
    "\n",
    "record = training(model, train_dataloader, valid_dataloader, epoch, loss_function, optimizer, early_stop_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(record)\n",
    "model.eval()\n",
    "loss, acc = evaluating(model, valid_dataloader, loss_function)\n",
    "print(f\"loss: {loss:.4f}, acc: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
